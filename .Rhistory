setwd("/Users/leonardo/Desktop/SM4HDD")
rm(list=ls())
# Install required package
if (!require(dplyr)) {
install.packages("dplyr")
}
if (!require(stringr)) {
install.packages("stringr")
}
if (!require(ggplot2)) {
install.packages("ggplot2")
}
if (!require(maps)) {
install.packages("maps")
}
if (!require(dplyr)) {
install.packages("dplyr")
}
if (!require(viridis)) {
install.packages("viridis")
}
if (!require(caret)) {
install.packages("caret")
}
if (!require(lattice)) {
install.packages("lattice")
}
if (!require(bestglm)) {
install.packages("bestglm")
}
if (!require(glmnet)) {
install.packages("glmnet")
}
if (!require(GGally)) {
install.packages("GGally")
}
if (!require(gglasso)) {
install.packages("gglasso")
}
if (!requireNamespace("sparseSVM", quietly = TRUE)) {
install.packages("sparseSVM")
}
if (!require(genlasso)) {
install.packages("genlasso")
}
# Load required libraries
library(ggplot2)
library(maps)
library(dplyr)
library(viridis)
library(stringr)
library(caret)
library(lattice)
library(bestglm)
library(glmnet)
library(Matrix)
library(GGally)
library(gglasso)
library(sparseSVM)
library(genlasso)
# 1) LOADING DATA
data <- read.csv("Data/Swarm_Behaviour.csv")
# Clearing the data: in the train set there are some NAs
data <- na.omit(data)
dim(data)
# change some data types
sapply(data, class)
data <- as.data.frame(apply(data, 2, as.numeric))  # Convert all variable types to numeric
sapply(data, class)                                # Print classes of all colums
# 2.1) Balanced classes?
table(data$Swarm_Behaviour)
# Setting seed for reproducibility
set.seed(123)
# Rebalance the classes deleting from class 0 until the classes are balanced
indices_class_0 <- which(data$Swarm_Behaviour == 0)
sampled_indices <- sample(indices_class_0, 7954)
new_class_0 <- data[sampled_indices, ]
indices_class_1 <- which(data$Swarm_Behaviour == 1)
sampled_indices1 <- sample(indices_class_1, 7954)
new_class_1 <- data[sampled_indices1, ]
data <- rbind(new_class_1, new_class_0)
# We can see now that the classes are balanced
table(data$Swarm_Behaviour)
# 2.2) Train test split
# Create an index for splitting the data
index <- createDataPartition(data$Swarm_Behaviour, p = 0.85, list = FALSE)
# Create training and testing sets
train <- data[index, ]
test <- data[-index, ]
# Define X_train and y_train
X_train <- train[, !names(train) %in% "Swarm_Behaviour"]  # Exclude the column "Swarm_Behaviour"
y_train <- train$Swarm_Behaviour
# Define X_test and y_test
X_test <- test[, !names(test) %in% "Swarm_Behaviour"]
y_test <- test$Swarm_Behaviour
# Print the dimensions of the resulting sets
cat("Dimensions of Training Set:", dim(train), "\n")
cat("Dimensions of Testing Set:", dim(test), "\n")
# Set the desired number of observations for the subsets (extract a subset of train for the cv)
desired_size_train <- 1000
# Randomly sample the specified number of observations for training set
sample_indices_train <- sample(1:nrow(X_train), size = desired_size_train, replace = FALSE)
X_train_cv <- X_train[sample_indices_train, ]
y_train_cv <- y_train[sample_indices_train]
# Print the dimensions of the resulting subsets
cat("Dimensions of X_train_cv:", dim(X_train_cv), "\n")
cat("Dimensions of y_train_cv:", length(y_train_cv), "\n")
# Count of 1s and 0s in the training set
table_y_train <- table(y_train)
cat("Training Set - Count of 1s:", table_y_train[["1"]], "\n")
cat("Training Set - Count of 0s:", table_y_train[["0"]], "\n")
# Count of 1s and 0s in the cross-validation training set
table_y_train_cv <- table(y_train_cv)
cat("CV Training Set - Count of 1s:", table_y_train_cv[["1"]], "\n")
cat("CV Training Set - Count of 0s:", table_y_train_cv[["0"]], "\n")
# 8) Generalized Lasso
# adjust type of X_train, ...
X_train <- as.matrix(X_train)
X_test <- as.matrix(X_test)
y_train <- as.vector(y_train)
y_test <- as.vector(y_test)
X_train_cv <- as.matrix(X_train_cv)
y_train_cv <- as.vector(y_train_cv)
# define the matrix of weights
D <- matrix(0, nrow = 2400-12, ncol = 2400)
for (i in 1:(2400-12)) {
idx <- seq(i, 2400, by = 12)
D[i, idx] <- 1
}
# defining a first model in order to retain the lambdas used in the build in cross validation
model_gen_final<-genlasso(y_train_cv, X_train_cv, D)
# plot the model
plot(model_gen_final)
# Predict on the test data
genlasso_predictions <- as.vector(predict(model_gen_final, newdata = as.matrix(X_test), lambda = best_lambda))$fit
best_lambda <- 30000
# Print the best lambda and its mean cross-validation loss
print(paste("Best Lambda:", best_lambda))
print(paste("Mean Cross-Validation Loss:", best_mean_cv_loss))
# Predict on the test data
genlasso_predictions <- as.vector(predict(model_gen_final, newdata = as.matrix(X_test), lambda = best_lambda))$fit
View(genlasso_predictions)
# Mean Squared Error
genlasso_mse <- mean((genlasso_predictions - y_test)^2)
print(paste("Mean Squared Error on Test Set:", genlasso_mse))
# Convert predictions to binary (e.g., using a threshold)
threshold <- 0.5
genlasso_binary_predictions <- ifelse(genlasso_predictions > threshold, 1, 0)
View(X_test)
# Calculate confusion matrix
genlasso_conf_matrix <- table(genlasso_binary_predictions, y_test)
print("Confusion Matrix:")
print(genlasso_conf_matrix)
print(paste("Mean Squared Error on Test Set:", genlasso_mse))
# Convert predictions to binary (e.g., using a threshold)
threshold <- 0.5
genlasso_binary_predictions <- ifelse(genlasso_predictions > threshold, 1, 0)
# Calculate confusion matrix
genlasso_conf_matrix <- table(genlasso_binary_predictions, y_test)
dim(genlasso_predictions)
dim(y_test)
# Predict on the test data
genlasso_predictions <- as.vector(predict(model_gen_final, newdata = as.matrix(X_test), lambda = best_lambda)$fit)
# Mean Squared Error
genlasso_mse <- mean((genlasso_predictions - y_test)^2)
print(paste("Mean Squared Error on Test Set:", genlasso_mse))
View(X_test)
View(X_train)
genlasso_predictions
View(X_train_cv)
as.matrix(X_test)
dim( as.matrix(X_test))
predict(model_gen_final, newdata = as.matrix(X_test), lambda = best_lambda)
p <- predict(model_gen_final, newdata = as.matrix(X_test), lambda = best_lambda
)
View(p)
p$lambda
p$df
p$fit
model_gen_final
View(model_gen_final)
# Predict on the test data
genlasso_predictions <- as.vector(predict(model_gen_final, Xnew = as.matrix(X_test), lambda = best_lambda)$fit)
# Mean Squared Error
genlasso_mse <- mean((genlasso_predictions - y_test)^2)
print(paste("Mean Squared Error on Test Set:", genlasso_mse))
# Convert predictions to binary (e.g., using a threshold)
threshold <- 0.5
genlasso_binary_predictions <- ifelse(genlasso_predictions > threshold, 1, 0)
# Calculate confusion matrix
genlasso_conf_matrix <- table(genlasso_binary_predictions, y_test)
print("Confusion Matrix:")
print(genlasso_conf_matrix)
# Calculate accuracy
genlasso_accuracy <- sum(diag(genlasso_conf_matrix)) / sum(genlasso_conf_matrix)
print(paste("Accuracy:", genlasso_accuracy))
# Precision
genlasso_precision <- genlasso_conf_matrix[2, 2] / sum(genlasso_conf_matrix[, 2])
print(paste("Precision:", genlasso_precision))
# Recall
genlasso_recall <- genlasso_conf_matrix[2, 2] / sum(genlasso_conf_matrix[2, ])
print(paste("Recall:", genlasso_recall))
